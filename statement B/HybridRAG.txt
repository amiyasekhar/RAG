import openai
import streamlit as st
import os
from dotenv import load_dotenv
from GraphRAG import build_knowledge_graph, graph_retrieve_entities
from VectorRAG import add_documents_to_index, vector_retrieve_documents
# from VectorRAG_with_faiss import add_documents_to_index, vector_retrieve_documents
import docx
import fitz  # PyMuPDF

# Load environment variables from the .env file
load_dotenv()

# Fetch the API key from the environment variables
openai.api_key = os.getenv('OPENAI_API_KEY')

# Streamlit interface setup
st.title("Hybrid RAG with FAISS")

# Query input using Streamlit's text input
query = st.text_input("Enter your query:")

# File uploader for accepting multiple files
uploaded_files = st.file_uploader("Upload your documents (PDF or DOCX)", type=["pdf", "docx"], accept_multiple_files=True)

# Function to combine results from both RAG approaches (VectorRAG and GraphRAG)
def hybrid_retrieve(query):
    # Retrieve unstructured data using VectorRAG
    vector_results = vector_retrieve_documents(query)
    
    # Retrieve structured data using GraphRAG
    graph_results = graph_retrieve_entities(query)
    
    return vector_results, graph_results

# OpenAI GPT generation function
def generate_response_from_hybrid_rag(query, retrieved_texts, retrieved_entities):
    custom_prompt = f"""
    You are a helpful assistant who queries the pleadings in a case. The pleadings are uploaded to your database. Only based on relevant information in a database are you to provide an answer. 
    
    Identify the Impugned Order:
    Scan the Index section for terms like "Impugned Order," "High Court Order," or equivalent keywords.
    Extract the annexure label (e.g., P-1, P-30) and the corresponding page numbers.
    Verify if the annexures contain a certified copy by checking for any certification stamps or noted mentions of certification.

    Summarize the Grounds:
    Look for a section explicitly titled "Grounds for Appeal," "Grounds,‚Äù or similar.
    Extract key arguments, legal principles, or points raised by the petitioner challenging the lower court's judgment.
    Summarize these grounds concisely while preserving key legal points and rationales.

    Summarize the Facts:
    Locate the "Statement of Facts," "Background Information," or similar section.
    Extract relevant chronological events, key figures involved, and context of the case.
    Provide a coherent, concise summary covering the essence of the case's background.

    Summarize the Prayers:
    Identify the section with "Prayers," "Relief Sought," or similar terminology.
    Extract specific reliefs or orders sought by the petitioner from the court.
    Summarize all reliefs concisely and clearly.

    Check for Office Objections:
    Match the petition content against a standardized list of common objections which are available in your database, such as:
    - Missing signatures
    - Non-filing of affidavits
    - Issues with Vakalatnama
    - Incorrect or missing translations
    - Incomplete or incorrect annexure labeling
    - Proof of proper certification for documents

    Highlight any discrepancies or missing elements based on this checklist.
    
    The following unstructured texts have been retrieved:
    {retrieved_texts}
    
    The following structured knowledge has been retrieved:
    {retrieved_entities}

    Based on this, provide a detailed answer to the query: {query}
    """
    
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": "You are a legal assistant."},
            {"role": "user", "content": custom_prompt}
        ]
    )
    # print(f"The response: {response}")
    return response.choices[0].message.content

# Function to extract text from a .docx file
def extract_text_from_docx(file_path):
    doc = docx.Document(file_path)
    full_text = []
    for para in doc.paragraphs:
        full_text.append(para.text)
    return '\n'.join(full_text)

# Function to extract text from a PDF file
def extract_text_from_pdf(pdf_file):
    doc = fitz.open(pdf_file)
    text = ""
    for page in doc:
        text += page.get_text()
    return text

# Main function to control the workflow
def main():
    # Step 1: Build the knowledge graph (GraphRAG)
    build_knowledge_graph()
    
    # Step 2: Extract text from documents
    slp_civil_text = extract_text_from_docx("./documents/Special Leave Petition Civil.docx")
    slp_criminal_text = extract_text_from_docx("./documents/Special Leave Petition Criminal.docx")
    civil_appeal_text = extract_text_from_docx("./documents/Civil Appeal - Super labels ltd...docx")
    defect_list_text = extract_text_from_pdf("./documents/Defects list as per Registry Supreme Court.pdf")
    form28_text = extract_text_from_pdf("./documents/Form 28.pdf")

    # Combine all extracted texts into one list
    documents = [slp_civil_text, defect_list_text, slp_criminal_text, civil_appeal_text, form28_text]
    
    # Step 3: Add documents to vector index (VectorRAG)
    add_documents_to_index(documents)
    
    # Step 4: Input query
    # query = "What is the Impugned Order?"
    query = "Does the Special Leave Petition Civil text have all the requirements of Form 28?"
    
    # Step 5: Hybrid retrieval (VectorRAG + GraphRAG)
    retrieved_texts, retrieved_entities = hybrid_retrieve(query)
    
    # Step 6: Generate response using OpenAI
    answer = generate_response_from_hybrid_rag(query, retrieved_texts, retrieved_entities)
    
    with open("./results/form28_no_faiss.txt", 'w') as file:
        file.write("Documents fed:\n")
        file.write("Special Leave Petition Civil.docx\n")
        file.write("Special Leave Petition Criminal.docx\n")
        file.write("Civil Appeal - Super labels ltd...docx\n")
        file.write("Defects list as per Registry Supreme Court.pdf\n")
        file.write("Form 28.pdf\n")
        file.write("\n")
        file.write(f"User query: {query}\n")
        file.write(answer)
    print(f"Answer to \"{query}\" written to file")
    # print(f"Answer: {answer}")

if __name__ == '__main__':
    main()